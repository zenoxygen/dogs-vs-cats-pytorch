{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8oGWQzxqB0Rm"
   },
   "source": [
    "# Dogs vs. Cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6fVdgG75ayQx"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sl9x3cBGB0R5"
   },
   "source": [
    "### Upload Kaggle API token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L8wjpwUBYoR_"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from google.colab import files\n",
    "\n",
    "kaggle_path = '/root/.kaggle'\n",
    "kaggle_dir = Path(kaggle_path)\n",
    "kaggle_api_token_filename = 'kaggle.json'\n",
    "kaggle_api_token_path = kaggle_dir/kaggle_api_token_filename\n",
    "\n",
    "# Upload your `kaggle.json` API token file\n",
    "uploaded = files.upload()\n",
    "for filename in uploaded.keys():\n",
    "    print(f'Successfully uploaded file `{filename}` ({len(uploaded[filename])} bytes)')\n",
    "\n",
    "# Then move `kaggle.json` into the folder where the API expects to find it\n",
    "! mkdir -p {kaggle_dir} && mv {kaggle_api_token_filename} {kaggle_dir} && chmod 600 {kaggle_api_token_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fGBcjYYBB0SF"
   },
   "source": [
    "### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wrgohac1CrU4"
   },
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "! kaggle competitions download -c 'dogs-vs-cats'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rM3YpfrzB0SN"
   },
   "source": [
    "### Define folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "96wvnIz2yHy1"
   },
   "outputs": [],
   "source": [
    "# Define the root directory\n",
    "data_dir = '/root/.kaggle/dogs-vs-cats'\n",
    "\n",
    "# Create the root directory\n",
    "! mkdir -p {data_dir}\n",
    "\n",
    "# Define training directory\n",
    "train_dir = f'{data_dir}/train'\n",
    "train_dog_dir = f'{train_dir}/dog'\n",
    "train_cat_dir = f'{train_dir}/cat'\n",
    "\n",
    "# Define validation directory\n",
    "val_dir = f'{data_dir}/val'\n",
    "val_dog_dir = f'{val_dir}/dog'\n",
    "val_cat_dir = f'{val_dir}/cat'\n",
    "\n",
    "# Create training directory\n",
    "! mkdir -p {train_dog_dir}\n",
    "! mkdir -p {train_cat_dir}\n",
    "\n",
    "# Create validation directory\n",
    "! mkdir -p {val_dog_dir}\n",
    "! mkdir -p {val_cat_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZzOqzAnMB0SU"
   },
   "source": [
    "### Unzip train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o90xUXo4B0SW"
   },
   "outputs": [],
   "source": [
    "# Unzip training dataset in the root directory\n",
    "! unzip train.zip -d {data_dir}\n",
    "\n",
    "# Print the number of dogs images\n",
    "print('Number of dogs images')\n",
    "! ls -1 {train_dir}/dog* | wc -l\n",
    "\n",
    "# Print the number of cats images\n",
    "print('Number of cats images')\n",
    "! ls -1 {train_dir}/cat* | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v4MhhKvPB0Sb"
   },
   "source": [
    "### Organize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lUJQUnaXolLK"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "# Move training images for a good folder structure\n",
    "files = os.listdir(train_dir)\n",
    "for filename in files:\n",
    "    dog_search = re.search('dog', filename)\n",
    "    cat_search = re.search('cat', filename)\n",
    "    if dog_search:\n",
    "        shutil.move(f'{train_dir}/{filename}', train_dog_dir)\n",
    "    elif cat_search:\n",
    "        shutil.move(f'{train_dir}/{filename}', train_cat_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "22eM5MSTzUNo"
   },
   "outputs": [],
   "source": [
    "# Take some dogs images from training dataset to build a validation dog dataset \n",
    "files = os.listdir(train_dog_dir)\n",
    "for filename in files:\n",
    "    dog_search = re.search(\"5\\d\\d\\d\", filename)\n",
    "    if dog_search:\n",
    "        shutil.move(f'{train_dog_dir}/{filename}', val_dog_dir)\n",
    "        \n",
    "# Take some cats images from training dataset to build a validation cat dataset \n",
    "files = os.listdir(train_cat_dir)\n",
    "for filename in files:\n",
    "    cat_search = re.search('5\\d\\d\\d', filename)\n",
    "    if cat_search:\n",
    "        shutil.move(f'{train_cat_dir}/{filename}', val_cat_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QlfIPPq3nAr0"
   },
   "outputs": [],
   "source": [
    "# Verify images\n",
    "print('Training dog dataset directory')\n",
    "! ls {train_dog_dir} | head -n 5\n",
    "print('Training cat dataset directory')\n",
    "! ls {train_cat_dir} | head -n 5\n",
    "\n",
    "print('Validation dog dataset directory')\n",
    "! ls {val_dog_dir} | head -n 5\n",
    "print('Validation cat dataset directory')\n",
    "! ls {val_cat_dir} | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "etRhdeqyB0St"
   },
   "source": [
    "### Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vLg90V4UWiR4"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Automatically use CUDA if it's enabled\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define transforms for the training data\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "# Define transforms for the validation data\n",
    "val_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                          [0.229, 0.224, 0.225])])\n",
    "\n",
    "# Pass transforms in here\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
    "val_data = datasets.ImageFolder(data_dir + '/val', transform=val_transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(val_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YU_WHsHZB0S2"
   },
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hh4kgbS1B0S5"
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = models.densenet121(pretrained=True)\n",
    "\n",
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace classifier\n",
    "model.classifier = nn.Sequential(nn.Linear(1024, 256),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(256, 2),\n",
    "                                 nn.LogSoftmax(dim=1))\n",
    "\n",
    "# Define criterion\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Only train the classifier parameters, feature parameters are frozen\n",
    "optimizer = optim.SGD(model.classifier.parameters(), lr=0.004)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6U_PqXQTB0S-"
   },
   "source": [
    "### Train neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CfevHZcNxgZq"
   },
   "outputs": [],
   "source": [
    "train_loss = 0\n",
    "\n",
    "for inputs, labels in trainloader:\n",
    "\n",
    "    # Move input and label tensors to the GPU\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    # Clear the gradients, do this because gradients are accumulated\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Make a forward pass through the network to get the outputs\n",
    "    outputs = model.forward(inputs)\n",
    "\n",
    "    # Use the logits to calculate the loss\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # Perform a backward pass through the network to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # Update train loss\n",
    "    train_loss += loss.item()\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Implement the validation pass\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "\n",
    "        for inputs, labels in testloader:\n",
    "            \n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Make a forward pass through the network to get the outputs\n",
    "            outputs = model.forward(inputs)\n",
    "                \n",
    "            # Use the outputs to calculate the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Update test loss\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Get the class probabilities\n",
    "            ps = torch.exp(outputs)\n",
    "\n",
    "            # Get the most likely class using the ps.topk method\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "\n",
    "            # Check if the predicted classes match the labels\n",
    "            equals = top_class == labels.view(*top_class.shape)\n",
    "\n",
    "            # Calculate the percentage of correct predictions\n",
    "            accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "            \n",
    "    # Set model back to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Print out the training loss, testing loss and validation accuracy\n",
    "    print(f'Train loss: {train_loss/len(trainloader):.3f}.. '\n",
    "          f'Test loss: {test_loss/len(testloader):.3f}.. '\n",
    "          f'Test accuracy: {accuracy/len(testloader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TichXHsWwUNK"
   },
   "outputs": [],
   "source": [
    "print('Our model: \\n\\n', model, '\\n')\n",
    "print('The state dict keys: \\n\\n', model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fCJ3zelhB0TJ"
   },
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pCtKtousFv3J"
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "checkpoint = {\n",
    "    'parameters' : model.parameters,\n",
    "    'state_dict' : model.state_dict()\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, './dogs-vs-cats.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dMEI49djB0TP"
   },
   "source": [
    "### Unzip test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g-Un5ZGbNfXB"
   },
   "outputs": [],
   "source": [
    "# Unzip competition test dataset\n",
    "! unzip test1.zip -d {data_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v8iKKdIUB0TV"
   },
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m8ziGcYQk7bm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def image_transform(image_path):\n",
    "    test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                          transforms.CenterCrop(224),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                               [0.229, 0.224, 0.225])])\n",
    "    image = Image.open(image_path)\n",
    "    image_tensor = test_transforms(image)\n",
    "    return image_tensor\n",
    "\n",
    "def image_show(image, ax=None, title=None, normalize=True):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    if normalize:\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.tick_params(axis='both', length=0)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5aEIAD907_WP"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Move model to CPU\n",
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Define test directory\n",
    "test_dir = f'{data_dir}/test1'\n",
    "\n",
    "# Get random image from test dataset\n",
    "image_path = f'{test_dir}/{random.randint(1, 12500)}.jpg'\n",
    "\n",
    "# Transform image\n",
    "image = image_transform(image_path)\n",
    "\n",
    "# Show image\n",
    "image_show(image)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Make prediction\n",
    "with torch.no_grad():\n",
    "    image = image[None,:,:,:]\n",
    "    ps = torch.exp(model(image))\n",
    "    top_p, top_class = ps.topk(1, dim=1)\n",
    "\n",
    "if top_class == 1:    \n",
    "    print(f'Class: dog (confidence: {top_p.item()})')\n",
    "else:\n",
    "    print(f'Class: cat (confidence: {top_p.item()})')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dogs_vs_cats.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
